{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "\n",
    "img_rows, img_cols =32, 32\n",
    "channels=3\n",
    "input_shape=(img_rows, img_cols, channels)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------- Preparing Data for Training -------------------------------------------------#\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def unpickle(file):\n",
    "    \n",
    "    with open(file, 'rb') as fo:\n",
    "       dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "    \n",
    "\n",
    "    \n",
    "def reshape_images_data_shape(raw_images_data):\n",
    "    \n",
    "    #Reshape to 4-dimensions - [image_number, channel, height, width]\n",
    "    images_data=raw_images_data.reshape([-1, channels, img_rows, img_cols])\n",
    "    #4D array - [image_number, height, width, channel]\n",
    "    images_data=images_data.transpose([0,2,3,1])\n",
    "    return images_data\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_data(file):\n",
    "    \n",
    "    data = unpickle(file)\n",
    "    \n",
    "    # Get raw images data\n",
    "    images_data =data[b'data']\n",
    "    # Reshape images_data\n",
    "    reshaped_images_data =reshape_images_data_shape(images_data)\n",
    "    \n",
    "    # Get lists of filenames and labels\n",
    "    filenames = [t.decode('utf8') for t in data[b'filenames']]\n",
    "    fine_labels = data[b'fine_labels']\n",
    "    coarse_labels= data[b'coarse_labels']\n",
    "    # Turn lists into numpy arrays\n",
    "    filenames=np.array(filenames)\n",
    "    fine_labels=np.array(fine_labels)\n",
    "    coarse_labels=np.array(coarse_labels)\n",
    "        \n",
    "    return reshaped_images_data, filenames, fine_labels, coarse_labels\n",
    "    \n",
    "    \n",
    "    \n",
    "def select_superclasses_indices(a,b, coarse_labels):\n",
    "    \n",
    "    indices=list()\n",
    "\n",
    "    for index in range(len(coarse_labels)):\n",
    "        if (coarse_labels[index]==a or coarse_labels[index]==b):\n",
    "            index_to_be_added=index\n",
    "            indices.append(index_to_be_added)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "def select_items(indices, data, filenames, fine_labels, coarse_labels):\n",
    "    \n",
    "    selected_filenames=filenames[indices]\n",
    "    selected_fine_labels=fine_labels[indices]\n",
    "    selected_coarse_labels=coarse_labels[indices]\n",
    "    \n",
    "    selected_data=data[indices, :]\n",
    "\n",
    "    return selected_data, selected_filenames, selected_fine_labels, selected_coarse_labels\n",
    "\n",
    "\n",
    "\n",
    "def change_class_encoding_numbers(class_encoding):\n",
    "    \n",
    "    # [cloud, forest, mountain, plain, sea, camel, cattle, chimpanzee, elephant, kangaroo]\n",
    "    # [23, 33, 49, 60, 71, 15, 19, 21, 31, 38]\n",
    "    # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]    \n",
    "  \n",
    "    initial_encoding=[23, 33, 49, 60, 71, 15, 19, 21, 31, 38]\n",
    "    final_encoding=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    " \n",
    "    d = dict(zip(initial_encoding, final_encoding))\n",
    "    \n",
    "    class_encoding_list=[d.get(e, e) for e in class_encoding]\n",
    "    class_encoding=np.array(class_encoding_list)\n",
    "    \n",
    "    return class_encoding\n",
    "\n",
    "\n",
    "\n",
    "def change_superclass_encoding_numbers(superclass_encoding):\n",
    "    \n",
    "    # [large natural outdoor scenes, large omnivores and herbivores]\n",
    "    # [10, 11]\n",
    "    # [0, 1]    \n",
    "  \n",
    "    initial_encoding=[10, 11]\n",
    "    final_encoding=[0, 1]\n",
    " \n",
    "    d = dict(zip(initial_encoding, final_encoding))\n",
    "    \n",
    "    superclass_encoding_list=[d.get(e, e) for e in superclass_encoding]\n",
    "    superclass_encoding=np.array(superclass_encoding_list)\n",
    "    \n",
    "    return superclass_encoding\n",
    "\n",
    "\n",
    "\n",
    "def classes_to_superclasses(predicted_classes):\n",
    "    \n",
    "    # [cloud, forest, mountain, plain, sea, camel, cattle, chimpanzee, elephant, kangaroo]\n",
    "    classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    superclasses = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "    \n",
    "    d = dict(zip(classes, superclasses))\n",
    "    \n",
    "    predicted_superclasses_list=[d.get(e, e) for e in predicted_classes]\n",
    "    predicted_superclasses=np.array(predicted_superclasses_list)\n",
    "    \n",
    "    return predicted_superclasses\n",
    "\n",
    "\n",
    "\n",
    "def get_train_data():\n",
    "    \n",
    "    data, filenames, fine_labels, coarse_labels = load_data('cifar-100-python/train')\n",
    "    indices=select_superclasses_indices(10, 11, coarse_labels)\n",
    "    train_data, train_filenames, train_fine_labels, train_coarse_labels = \\\n",
    "    select_items(indices, data, filenames, fine_labels, coarse_labels)\n",
    "    \n",
    "    train_classes=change_class_encoding_numbers(train_fine_labels)\n",
    "    train_superclasses=change_superclass_encoding_numbers(train_coarse_labels)\n",
    "        \n",
    "    return train_data, train_filenames, train_fine_labels, train_coarse_labels, train_classes, train_superclasses\n",
    "\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "    \n",
    "    data, filenames, fine_labels, coarse_labels = load_data('cifar-100-python/test')\n",
    "    indices=select_superclasses_indices(10, 11, coarse_labels)\n",
    "    test_data, test_filenames, test_fine_labels, test_coarse_labels = \\\n",
    "    select_items(indices, data, filenames, fine_labels, coarse_labels)\n",
    "\n",
    "    test_classes=change_class_encoding_numbers(test_fine_labels)\n",
    "    test_superclasses=change_superclass_encoding_numbers(test_coarse_labels)\n",
    "    \n",
    "    np.save('test_data.npy',test_data)\n",
    "    np.save('test_classes.npy',test_classes)\n",
    "    \n",
    "    return test_data, test_filenames, test_fine_labels, test_coarse_labels, test_classes, test_superclasses\n",
    "\n",
    "\n",
    "\n",
    "def create_train_validation_partition(X, y, validation_size):\n",
    "    \n",
    "    train_partition_data, validation_partition_data, train_partition_classes, validation_partition_classes = \\\n",
    "    train_test_split(X, y, test_size=validation_size, stratify=y)\n",
    "    \n",
    "    np.save('train_partition_data.npy',train_partition_data)\n",
    "    np.save('train_partition_classes.npy',train_partition_classes)\n",
    "    np.save('validation_partition_data.npy',validation_partition_data)\n",
    "    np.save('validation_partition_classes.npy',validation_partition_classes)\n",
    "    \n",
    "    return train_partition_data, validation_partition_data, train_partition_classes, validation_partition_classes\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "#----------------------------------- Classification Report -------------------------------------------------------#\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def plot_history(history):\n",
    "    mean_squared_error_list = [s for s in history.history.keys() if 'mean_squared_error' in s and 'val' not in s]\n",
    "    val_mean_squared_error_list = [s for s in history.history.keys() if 'mean_squared_error' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(mean_squared_error_list) == 0:\n",
    "        print('mean_squared_error is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As MSE always exists\n",
    "    epochs = range(1,len(history.history[mean_squared_error_list[0]]) + 1)\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    ## MSE\n",
    "    plt.figure(1)\n",
    "    for l in mean_squared_error_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training MSE (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_mean_squared_error_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation MSE (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('MSE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    \n",
    "    return \n",
    " \n",
    "    \n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, cmap=plt.cm.Blues):\n",
    "                                       \n",
    "    # This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title='Normalized confusion matrix'\n",
    "    else:\n",
    "        title='Confusion matrix'\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "    \n",
    "def print_classification_report(test_classes, test_superclasses):\n",
    "    \n",
    "    y_test_classes = np.argmax(test_classes, axis=1) # Convert one-hot to index\n",
    "    \n",
    "    y_pred_classes = model.predict_classes(test_data)\n",
    "    y_pred_superclasses = classes_to_superclasses(y_pred_classes)\n",
    "      \n",
    "    # Report for classes\n",
    "    print(\"______________________________CLASSES______________________________\\n\")\n",
    "    \n",
    "    Accuracy= accuracy_score(y_test_classes, y_pred_classes)\n",
    "    print(\"Total Classes Accuracy= \",Accuracy,\"\\n\")\n",
    "    \n",
    "    print(classification_report(y_test_classes, y_pred_classes))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=[0,1,2,3,4,5,6,7,8,9])\n",
    "     \n",
    "    # Report for superclasses\n",
    "    print(\"______________________________SUPERCLASSES______________________________\\n\")\n",
    "    \n",
    "    Accuracy= accuracy_score(test_superclasses, y_pred_superclasses)\n",
    "    print(\"Total Superclasses Accuracy= \",Accuracy,\"\\n\")\n",
    "    \n",
    "    print(classification_report(test_superclasses, y_pred_superclasses))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(test_superclasses, y_pred_superclasses)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=[0,1])\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "#--------------------------------------------- ROCS --------------------------------------------------------------#\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def plot_specific_class_ROC(class_index):\n",
    "   \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[class_index], tpr[class_index], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[class_index])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC - class %i' % class_index)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def plot_multiclass_ROC(n_classes):\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'purple', 'red', 'green', 'dimgrey', 'yellow', 'deepskyblue', 'navy'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-class ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def compute_and_plot_ROC(y_test, y_score):\n",
    "\n",
    "    y = label_binarize(y_test, classes=[0,1,2,3,4,5,6,7,8,9])\n",
    "    n_classes = y.shape[1]\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    print(\"------------------------ROC per Class------------------------\\n\")\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        plot_specific_class_ROC(i)\n",
    "    \n",
    "    print(\"------------------------Multiclass ROC------------------------\\n\")\n",
    "    \n",
    "    plot_multiclass_ROC(n_classes)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
