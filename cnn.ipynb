{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import keras\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.utils import np_utils\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# My imports\n",
    "from my_functions import get_train_data, get_test_data, create_train_validation_partition, classes_to_superclasses\n",
    "\n",
    "# Image parameters\n",
    "IMG_ROWS, IMG_COLS =32, 32\n",
    "CHANNELS=3\n",
    "INPUT_SHAPE=(IMG_ROWS, IMG_COLS, CHANNELS)\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# Load train set\n",
    "train_data, train_filenames, train_fine_labels, train_coarse_labels, train_classes, train_superclasses = get_train_data()\n",
    "\n",
    "# Load test set\n",
    "test_data, test_filenames, test_fine_labels, test_coarse_labels, test_classes, test_superclasses = get_test_data()\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# Turn classes into one-hot-vectors\n",
    "train_classes = np_utils.to_categorical(train_classes, 10)\n",
    "test_classes = np_utils.to_categorical(test_classes, 10)\n",
    "\n",
    "# Create train - validation partitions from the inital train set\n",
    "train_partition_data, validation_partition_data, train_partition_classes, validation_partition_classes = create_train_validation_partition(train_data, train_classes, 0.1)\n",
    "\n",
    "# Call data generators\n",
    "train_datagen  = ImageDataGenerator()\n",
    "\n",
    "valid_datagen = ImageDataGenerator()    \n",
    "\n",
    "train_datagen.fit(train_partition_data)\n",
    "valid_datagen.fit(validation_partition_data)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# Create model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy', 'mse'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=4, min_delta=0.001, cooldown=5, min_lr=0.0001)\n",
    "mcp_save = ModelCheckpoint('.mdl_wts_no_augmentation.hdf5', save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min')\n",
    "\n",
    "history = model.fit_generator(\n",
    "            train_datagen.flow(train_partition_data, train_partition_classes, batch_size=128),\n",
    "            steps_per_epoch=200,\n",
    "            epochs=26,\n",
    "            validation_data=valid_datagen.flow(validation_partition_data, validation_partition_classes, batch_size=12),\n",
    "            validation_steps=50,\n",
    "            callbacks=[early_stopping, reduce_lr, mcp_save])\n",
    "\n",
    "scores = model.evaluate(test_data, test_classes, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "print('Test MSE:', scores[2])\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    mean_squared_error_list = [s for s in history.history.keys() if 'mean_squared_error' in s and 'val' not in s]\n",
    "    val_mean_squared_error_list = [s for s in history.history.keys() if 'mean_squared_error' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(mean_squared_error_list) == 0:\n",
    "        print('mean_squared_error is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As MSE always exists\n",
    "    epochs = range(1,len(history.history[mean_squared_error_list[0]]) + 1)\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    ## MSE\n",
    "    plt.figure(1)\n",
    "    for l in mean_squared_error_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training MSE (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_mean_squared_error_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation MSE (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('MSE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    \n",
    "    return \n",
    " \n",
    "    \n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, cmap=plt.cm.Blues):\n",
    "                                       \n",
    "    # This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title='Normalized confusion matrix'\n",
    "    else:\n",
    "        title='Confusion matrix'\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "    \n",
    "def print_classification_report(test_classes, test_superclasses):\n",
    "    \n",
    "    y_test_classes = np.argmax(test_classes, axis=1) # Convert one-hot to index\n",
    "    \n",
    "    y_pred_classes = model.predict_classes(test_data)\n",
    "    y_pred_superclasses = classes_to_superclasses(y_pred_classes)\n",
    "      \n",
    "    # Report for classes\n",
    "    print(\"______________________________CLASSES______________________________\\n\")\n",
    "    \n",
    "    Accuracy= accuracy_score(y_test_classes, y_pred_classes)\n",
    "    print(\"Total Classes Accuracy= \",Accuracy,\"\\n\")\n",
    "    \n",
    "    print(classification_report(y_test_classes, y_pred_classes))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=[0,1,2,3,4,5,6,7,8,9])\n",
    "     \n",
    "    # Report for superclasses\n",
    "    print(\"______________________________SUPERCLASSES______________________________\\n\")\n",
    "    \n",
    "    Accuracy= accuracy_score(test_superclasses, y_pred_superclasses)\n",
    "    print(\"Total Superclasses Accuracy= \",Accuracy,\"\\n\")\n",
    "    \n",
    "    print(classification_report(test_superclasses, y_pred_superclasses))\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(test_superclasses, y_pred_superclasses)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=[0,1])\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "print_classification_report(test_classes, test_superclasses)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "y_test=test_classes\n",
    "y_test_classes = np.argmax(test_classes, axis=1) # Convert one-hot to index\n",
    "\n",
    "y_pred_classes = model.predict_classes(test_data)\n",
    "\n",
    "y_pred_probabilities = model.predict(test_data)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "y = label_binarize(y_test, classes=[0,1,2,3,4,5,6,7,8,9])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_probabilities[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred_probabilities.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "def plot_specific_class_ROC(class_index):\n",
    "   \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[class_index], tpr[class_index], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[class_index])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC - class %i' % class_index)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plot_specific_class_ROC(i)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "def plot_multiclass_ROC(n_classes):\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'purple', 'red', 'green', 'dimgrey', 'yellow', 'deepskyblue', 'navy'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-class ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "lw=2\n",
    "plot_multiclass_ROC(n_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
